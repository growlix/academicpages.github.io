---
title: "Single-trial decoding of intended eye movement goals from lateral
prefrontal cortex neural ensembles"
collection: publications
permalink:
date: 2015-11-09
venue: 'Journal of Neurophysiology'
paperurl: 'https://www.physiology.org/doi/abs/10.1152/jn.00788.2015'
citation: CB Boulay, F Pieper, <b>M Leavitt</b>, J Martinez-Trujillo, AJ Sachs
image: /images/publications-2015-11-09-decoding-eye-movements-from-lpfc-image.png
---
<i>Accessible abstract:</i> Recent advances in neural prosthetics research have made it such that controlling a robot arm with one’s brain activity is no longer a sci-fi pipedream. Most neural prosthetics decode signals from motor cortex and convert them into commands for effectors such as robot arms and computer cursors. Signals in motor cortex are effector-specific and immediate; “move your arm like this, right now”. The ability to decode intended goals in a more abstract form, prior to movement initiation could yield a uniquely powerful and flexible kind of neural prosthetic.<br><br>Neurons in the lateral prefrontal cortex (LPFC) encode signals for goal-directed actions, thus the LPFC might be a good signal source for such a goal-selection brain-computer interface (BCI). As a first step in the development of a goal-selection BCI, we set out to determine if we could decode simple behavioral intentions to direct gaze to different locations in space from LPFC neural activity. We compared a number of different decoding algorithms, and found that is indeed possible to decode intended saccade target location from single-trial LPFC activity. This suggests that the <b>LPFC is a suitable region for a goal-selection (or cognitive) BCI</b>.
